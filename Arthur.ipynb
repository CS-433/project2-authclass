{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>flair</th>\n",
       "      <th>N</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>1855</td>\n",
       "      <td>--fr0stbit3--</td>\n",
       "      <td>N:🇺🇸  A2:🇪🇸</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['es']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>1118</td>\n",
       "      <td>-TNB-o-</td>\n",
       "      <td>🇺🇸 -&gt; 🇯🇵</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>1319</td>\n",
       "      <td>-Vampires-</td>\n",
       "      <td>EN | ES | CN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>813</td>\n",
       "      <td>-tobyt</td>\n",
       "      <td>N 🇬🇧 | B2 🇪🇸 | B1 🇫🇷</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['fr']</td>\n",
       "      <td>['es']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>1485</td>\n",
       "      <td>-wojteq-</td>\n",
       "      <td>🇵🇱 N | 🇬🇧 B2 | 🇷🇺 A1</td>\n",
       "      <td>['pl']</td>\n",
       "      <td>['ru']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>1139</td>\n",
       "      <td>069988244</td>\n",
       "      <td>N🇬🇧 | 🇫🇷</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>900</td>\n",
       "      <td>0mnicious</td>\n",
       "      <td>🇬🇧 🇵🇹 N | 🇮🇹 B1 🇯🇵 A2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>918</td>\n",
       "      <td>1001010010012</td>\n",
       "      <td>🇪🇦 N 🇺🇸 C1 🇲🇫 B2</td>\n",
       "      <td>['es']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['fr']</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>1172</td>\n",
       "      <td>1020randomperson</td>\n",
       "      <td>🇰🇷 | 🏴󠁧󠁢󠁥󠁮󠁧󠁿🇯🇵 | 🇫🇷 | 🇬🇪</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>410</td>\n",
       "      <td>11abjurer</td>\n",
       "      <td>le epic flair</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>383</td>\n",
       "      <td>12034210124802140</td>\n",
       "      <td>eng,spa,port,ita,chi</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>1761</td>\n",
       "      <td>12the3</td>\n",
       "      <td>N🇵🇦🇺🇸|B2-C1🇨🇳|B2ish🇧🇷|B1🇫🇷|A2🇯🇵</td>\n",
       "      <td>[None]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['ja']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['zh']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>879</td>\n",
       "      <td>1433165A</td>\n",
       "      <td>🇪🇸N,🇺🇸C2,🇩🇪C2, 🇨🇳HSK3</td>\n",
       "      <td>['es']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['en', 'de']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>294</td>\n",
       "      <td>144_c</td>\n",
       "      <td>Learning Es</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>1659</td>\n",
       "      <td>1Pengor1</td>\n",
       "      <td>🇷🇺N | 🇰🇬N | 🇰🇿N | 🇺🇸C2 | 🇩🇪A1 | 🇺🇦</td>\n",
       "      <td>['ru', None, None]</td>\n",
       "      <td>['de']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['en']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>462</td>\n",
       "      <td>1ast0ne</td>\n",
       "      <td>🇺🇸N | 🇩🇪B1 🇪🇸 B1 | trying out: 🇦🇪 🇭🇹 🇮🇪</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['de', 'es']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>492</td>\n",
       "      <td>1min_map</td>\n",
       "      <td>🇭🇺 | 🇬🇧 🇵🇱 🇩🇪 🇻🇦</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>1170</td>\n",
       "      <td>27justin</td>\n",
       "      <td>🇩🇪 N | 🇺🇸 C2 | 🇯🇵 B1 | Planned 🇰🇷 🇻🇳 🇭🇰</td>\n",
       "      <td>['de']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['ja']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['en']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>2061</td>\n",
       "      <td>2Zzephyr</td>\n",
       "      <td>FR (N) | EN (Fluent) | Swedish Beginner</td>\n",
       "      <td>['FR']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>649</td>\n",
       "      <td>2plash6</td>\n",
       "      <td>🇺🇸N🇷🇺Тrуing му беsт🇪🇸HS Only</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0             author                                    flair  \\\n",
       "1855        1855      --fr0stbit3--                              N:🇺🇸  A2:🇪🇸   \n",
       "1118        1118            -TNB-o-                                 🇺🇸 -> 🇯🇵   \n",
       "1319        1319         -Vampires-                             EN | ES | CN   \n",
       "813          813             -tobyt                     N 🇬🇧 | B2 🇪🇸 | B1 🇫🇷   \n",
       "1485        1485           -wojteq-                     🇵🇱 N | 🇬🇧 B2 | 🇷🇺 A1   \n",
       "1139        1139          069988244                                 N🇬🇧 | 🇫🇷   \n",
       "900          900          0mnicious                    🇬🇧 🇵🇹 N | 🇮🇹 B1 🇯🇵 A2   \n",
       "918          918      1001010010012                        🇪🇦 N 🇺🇸 C1 🇲🇫 B2    \n",
       "1172        1172   1020randomperson                 🇰🇷 | 🏴󠁧󠁢󠁥󠁮󠁧󠁿🇯🇵 | 🇫🇷 | 🇬🇪   \n",
       "410          410          11abjurer                            le epic flair   \n",
       "383          383  12034210124802140                     eng,spa,port,ita,chi   \n",
       "1761        1761             12the3          N🇵🇦🇺🇸|B2-C1🇨🇳|B2ish🇧🇷|B1🇫🇷|A2🇯🇵   \n",
       "879          879           1433165A                    🇪🇸N,🇺🇸C2,🇩🇪C2, 🇨🇳HSK3   \n",
       "294          294              144_c                             Learning Es    \n",
       "1659        1659           1Pengor1       🇷🇺N | 🇰🇬N | 🇰🇿N | 🇺🇸C2 | 🇩🇪A1 | 🇺🇦   \n",
       "462          462            1ast0ne  🇺🇸N | 🇩🇪B1 🇪🇸 B1 | trying out: 🇦🇪 🇭🇹 🇮🇪   \n",
       "492          492           1min_map                         🇭🇺 | 🇬🇧 🇵🇱 🇩🇪 🇻🇦   \n",
       "1170        1170           27justin  🇩🇪 N | 🇺🇸 C2 | 🇯🇵 B1 | Planned 🇰🇷 🇻🇳 🇭🇰   \n",
       "2061        2061           2Zzephyr  FR (N) | EN (Fluent) | Swedish Beginner   \n",
       "649          649            2plash6             🇺🇸N🇷🇺Тrуing му беsт🇪🇸HS Only   \n",
       "\n",
       "                       N      A1      A2            B1      B2      C1  \\\n",
       "1855              ['en']      []  ['es']            []      []      []   \n",
       "1118                  []      []      []            []      []      []   \n",
       "1319                  []      []      []            []      []      []   \n",
       "813               ['en']      []      []        ['fr']  ['es']      []   \n",
       "1485              ['pl']  ['ru']      []            []  ['en']      []   \n",
       "1139              ['en']      []      []            []      []      []   \n",
       "900                   []      []      []            []      []      []   \n",
       "918               ['es']      []      []            []  ['fr']  ['en']   \n",
       "1172                  []      []      []            []      []      []   \n",
       "410                   []      []      []            []      []      []   \n",
       "383                   []      []      []            []      []      []   \n",
       "1761              [None]      []  ['ja']            []      []  ['zh']   \n",
       "879               ['es']      []      []            []      []      []   \n",
       "294                   []      []      []            []      []      []   \n",
       "1659  ['ru', None, None]  ['de']      []            []      []      []   \n",
       "462               ['en']      []      []  ['de', 'es']      []      []   \n",
       "492                   []      []      []            []      []      []   \n",
       "1170              ['de']      []      []        ['ja']      []      []   \n",
       "2061              ['FR']      []      []            []      []      []   \n",
       "649               ['en']      []      []            []      []      []   \n",
       "\n",
       "                C2  \n",
       "1855            []  \n",
       "1118            []  \n",
       "1319            []  \n",
       "813             []  \n",
       "1485            []  \n",
       "1139            []  \n",
       "900             []  \n",
       "918             []  \n",
       "1172            []  \n",
       "410             []  \n",
       "383             []  \n",
       "1761            []  \n",
       "879   ['en', 'de']  \n",
       "294             []  \n",
       "1659        ['en']  \n",
       "462             []  \n",
       "492             []  \n",
       "1170        ['en']  \n",
       "2061            []  \n",
       "649             []  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_levels_df = pd.read_csv('Data/user_levels.csv')\n",
    "user_levels_df.sort_values(by = 'author', ascending = True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first want to keep only the native english speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains  825  native english speakers.\n"
     ]
    }
   ],
   "source": [
    "print('The dataset contains ', user_levels_df['N'].str.contains('en|EN|En|eN').sum(), ' native english speakers.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>flair</th>\n",
       "      <th>N</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>1855</td>\n",
       "      <td>--fr0stbit3--</td>\n",
       "      <td>N:🇺🇸  A2:🇪🇸</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['es']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>813</td>\n",
       "      <td>-tobyt</td>\n",
       "      <td>N 🇬🇧 | B2 🇪🇸 | B1 🇫🇷</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['fr']</td>\n",
       "      <td>['es']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>1139</td>\n",
       "      <td>069988244</td>\n",
       "      <td>N🇬🇧 | 🇫🇷</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>462</td>\n",
       "      <td>1ast0ne</td>\n",
       "      <td>🇺🇸N | 🇩🇪B1 🇪🇸 B1 | trying out: 🇦🇪 🇭🇹 🇮🇪</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['de', 'es']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>649</td>\n",
       "      <td>2plash6</td>\n",
       "      <td>🇺🇸N🇷🇺Тrуing му беsт🇪🇸HS Only</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>1993</td>\n",
       "      <td>yxngfabio</td>\n",
       "      <td>🇺🇸 N | 🇪🇸 C1 | 🇧🇷 C1 | 🇷🇺 B1 | 🇨🇳 HSK1</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['ru']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['es', 'pt']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>1944</td>\n",
       "      <td>zamo555</td>\n",
       "      <td>🇬🇧N | 🇫🇷🇰🇷A2</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>595</td>\n",
       "      <td>zazzerida</td>\n",
       "      <td>En N | Fr B2; Es A2; It A2; De A2</td>\n",
       "      <td>['En']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Es', 'It', 'De']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Fr']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>367</td>\n",
       "      <td>zealouspilgrim</td>\n",
       "      <td>Native: 🇨🇦 | Learning: ht</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>1789</td>\n",
       "      <td>ztsmyder</td>\n",
       "      <td>🇺🇸(Native) 🇳🇴(A2)</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['no']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>825 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0          author                                    flair  \\\n",
       "1855        1855   --fr0stbit3--                              N:🇺🇸  A2:🇪🇸   \n",
       "813          813          -tobyt                     N 🇬🇧 | B2 🇪🇸 | B1 🇫🇷   \n",
       "1139        1139       069988244                                 N🇬🇧 | 🇫🇷   \n",
       "462          462         1ast0ne  🇺🇸N | 🇩🇪B1 🇪🇸 B1 | trying out: 🇦🇪 🇭🇹 🇮🇪   \n",
       "649          649         2plash6             🇺🇸N🇷🇺Тrуing му беsт🇪🇸HS Only   \n",
       "...          ...             ...                                      ...   \n",
       "1993        1993       yxngfabio   🇺🇸 N | 🇪🇸 C1 | 🇧🇷 C1 | 🇷🇺 B1 | 🇨🇳 HSK1   \n",
       "1944        1944         zamo555                             🇬🇧N | 🇫🇷🇰🇷A2   \n",
       "595          595       zazzerida        En N | Fr B2; Es A2; It A2; De A2   \n",
       "367          367  zealouspilgrim                Native: 🇨🇦 | Learning: ht   \n",
       "1789        1789        ztsmyder                        🇺🇸(Native) 🇳🇴(A2)   \n",
       "\n",
       "           N  A1                  A2            B1      B2            C1  C2  \n",
       "1855  ['en']  []              ['es']            []      []            []  []  \n",
       "813   ['en']  []                  []        ['fr']  ['es']            []  []  \n",
       "1139  ['en']  []                  []            []      []            []  []  \n",
       "462   ['en']  []                  []  ['de', 'es']      []            []  []  \n",
       "649   ['en']  []                  []            []      []            []  []  \n",
       "...      ...  ..                 ...           ...     ...           ...  ..  \n",
       "1993  ['en']  []                  []        ['ru']      []  ['es', 'pt']  []  \n",
       "1944  ['en']  []                  []            []      []            []  []  \n",
       "595   ['En']  []  ['Es', 'It', 'De']            []  ['Fr']            []  []  \n",
       "367   ['en']  []                  []            []      []            []  []  \n",
       "1789  ['en']  []              ['no']            []      []            []  []  \n",
       "\n",
       "[825 rows x 10 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "native_english_df = user_levels_df[user_levels_df['N'].str.contains('en|EN|En|eN')]\n",
    "native_english_df.sort_values(by = 'author', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we load the comments from all the native english speakers authors to add a column \"comments\" and statistics about this comments in the main dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeNoThinkyBrain is suspended.\n",
      "LiterallySoFamous is suspended.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>N</th>\n",
       "      <th>comments</th>\n",
       "      <th>nb_comments</th>\n",
       "      <th>average_nb_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Noktilucent</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[The crossover we need, not the crossover we d...</td>\n",
       "      <td>508.0</td>\n",
       "      <td>38.811024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ii_akinae_ii</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[what's your treatment regimen?  for me person...</td>\n",
       "      <td>955.0</td>\n",
       "      <td>60.512042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xanthic_strath</td>\n",
       "      <td>['En']</td>\n",
       "      <td>[Hello, u/SirGeeseGoose, and thank you for pos...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>106.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SageEel</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[mi olin e ni: jan mute li ken kepeken e toki ...</td>\n",
       "      <td>924.0</td>\n",
       "      <td>24.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dlt529</td>\n",
       "      <td>['EN']</td>\n",
       "      <td>[All of the above. \\n\\nImmersion/input is the ...</td>\n",
       "      <td>752.0</td>\n",
       "      <td>101.589096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>IAmGilGunderson</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[If you can look at what you have done and lea...</td>\n",
       "      <td>999.0</td>\n",
       "      <td>70.700701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>StrongIslandPiper</td>\n",
       "      <td>['EN']</td>\n",
       "      <td>[Just checked out the original post and tons o...</td>\n",
       "      <td>996.0</td>\n",
       "      <td>72.377510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Brxek0</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[A custom hercule is atletas high A tier, Cust...</td>\n",
       "      <td>794.0</td>\n",
       "      <td>5.802267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>taknyos</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[I was at WWE in the odyssey around that time ...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>56.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LeenaJones</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[Pimsleur and a ton of CI videos would probabl...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>93.131000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>the_paytonium</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[All of them., Hey man it's all good. I'm more...</td>\n",
       "      <td>260.0</td>\n",
       "      <td>53.484615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BeckyLiBei</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[Enjoy the challenge!  Chinese is hard., Sorry...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>57.776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RihanCastel</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[Who in the fuck learns a language for communi...</td>\n",
       "      <td>490.0</td>\n",
       "      <td>22.661224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>triosway</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[Very likely banned. Throwing things on the co...</td>\n",
       "      <td>999.0</td>\n",
       "      <td>26.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>furyousferret</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[When I was a monoglot English speaker, I used...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>39.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Lord_Zaoxc</td>\n",
       "      <td>['En']</td>\n",
       "      <td>[This is exactly the solution. I second record...</td>\n",
       "      <td>486.0</td>\n",
       "      <td>50.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>reasonisaremedy</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[Wie originell 🙄, You said what I wanted to: t...</td>\n",
       "      <td>996.0</td>\n",
       "      <td>101.141566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Maximum_Pie_6883</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[Yeah I remember back in high school learning ...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>48.344262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>greyslopp</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[Gross, Arent nunchucks quicker?, Vark leader ...</td>\n",
       "      <td>999.0</td>\n",
       "      <td>11.028028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>amazinggrace725</td>\n",
       "      <td>['en']</td>\n",
       "      <td>[What happened to that poor kid? That looks ba...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>19.459000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author       N  \\\n",
       "2         Noktilucent  ['en']   \n",
       "9        ii_akinae_ii  ['en']   \n",
       "12     xanthic_strath  ['En']   \n",
       "13            SageEel  ['en']   \n",
       "15             dlt529  ['EN']   \n",
       "16    IAmGilGunderson  ['en']   \n",
       "18  StrongIslandPiper  ['EN']   \n",
       "19             Brxek0  ['en']   \n",
       "21            taknyos  ['en']   \n",
       "22         LeenaJones  ['en']   \n",
       "23      the_paytonium  ['en']   \n",
       "25         BeckyLiBei  ['en']   \n",
       "29        RihanCastel  ['en']   \n",
       "35           triosway  ['en']   \n",
       "37      furyousferret  ['en']   \n",
       "38         Lord_Zaoxc  ['En']   \n",
       "39    reasonisaremedy  ['en']   \n",
       "42   Maximum_Pie_6883  ['en']   \n",
       "43          greyslopp  ['en']   \n",
       "45    amazinggrace725  ['en']   \n",
       "\n",
       "                                             comments  nb_comments  \\\n",
       "2   [The crossover we need, not the crossover we d...        508.0   \n",
       "9   [what's your treatment regimen?  for me person...        955.0   \n",
       "12  [Hello, u/SirGeeseGoose, and thank you for pos...       1000.0   \n",
       "13  [mi olin e ni: jan mute li ken kepeken e toki ...        924.0   \n",
       "15  [All of the above. \\n\\nImmersion/input is the ...        752.0   \n",
       "16  [If you can look at what you have done and lea...        999.0   \n",
       "18  [Just checked out the original post and tons o...        996.0   \n",
       "19  [A custom hercule is atletas high A tier, Cust...        794.0   \n",
       "21  [I was at WWE in the odyssey around that time ...       1000.0   \n",
       "22  [Pimsleur and a ton of CI videos would probabl...       1000.0   \n",
       "23  [All of them., Hey man it's all good. I'm more...        260.0   \n",
       "25  [Enjoy the challenge!  Chinese is hard., Sorry...       1000.0   \n",
       "29  [Who in the fuck learns a language for communi...        490.0   \n",
       "35  [Very likely banned. Throwing things on the co...        999.0   \n",
       "37  [When I was a monoglot English speaker, I used...       1000.0   \n",
       "38  [This is exactly the solution. I second record...        486.0   \n",
       "39  [Wie originell 🙄, You said what I wanted to: t...        996.0   \n",
       "42  [Yeah I remember back in high school learning ...         61.0   \n",
       "43  [Gross, Arent nunchucks quicker?, Vark leader ...        999.0   \n",
       "45  [What happened to that poor kid? That looks ba...       1000.0   \n",
       "\n",
       "    average_nb_words  \n",
       "2          38.811024  \n",
       "9          60.512042  \n",
       "12        106.770000  \n",
       "13         24.590909  \n",
       "15        101.589096  \n",
       "16         70.700701  \n",
       "18         72.377510  \n",
       "19          5.802267  \n",
       "21         56.460000  \n",
       "22         93.131000  \n",
       "23         53.484615  \n",
       "25         57.776000  \n",
       "29         22.661224  \n",
       "35         26.888889  \n",
       "37         39.013000  \n",
       "38         50.388889  \n",
       "39        101.141566  \n",
       "42         48.344262  \n",
       "43         11.028028  \n",
       "45         19.459000  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce the main dataframe to the column of interest  \n",
    "native_english_df = native_english_df[['author', 'N']]\n",
    "# path to my json files folder\n",
    "path_to_json = 'Data/user_comments/'\n",
    "# initialize empty array to construct the new columns in the for loop afterwards\n",
    "body = []\n",
    "average_number_of_words = []\n",
    "number_of_comments = []\n",
    "\n",
    "# Look through all the native english authors .json to extract the comments and their statistics : average number of words and number of comments per author \n",
    "for index, row in native_english_df.iterrows():\n",
    "    df = pd.read_json(path_to_json + row['author'] + '.json')\n",
    "    # Some author doesn't have any comments in their json files because they are suspended\n",
    "    # We fill their values with NaNs\n",
    "    if (df.iloc[0][0] == 'suspended'):\n",
    "        print(row['author'], \"is suspended.\")\n",
    "        body.append(np.NaN)\n",
    "        average_number_of_words.append(np.NaN)\n",
    "        number_of_comments.append(np.NaN)\n",
    "    # For the other authors, all the comments are put in a list, \n",
    "    # we count the number of words in average and the number of comments\n",
    "    else:\n",
    "        body.append(df.body.to_list())\n",
    "        average_number_of_words.append(df['body'].apply(lambda n: len(n.split())).mean())\n",
    "        number_of_comments.append(len(df.body))\n",
    "\n",
    "# Add columns of comments, average number of words per comment and number of comments to the main dataframe\n",
    "native_english_df['comments'] = body \n",
    "native_english_df['nb_comments'] = number_of_comments\n",
    "native_english_df['average_nb_words'] = average_number_of_words\n",
    "\n",
    "native_english_df.head(20)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then explore the statistics of the different authors in order to eliminate the outliers, standardize, normalize, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>823.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>617.393682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>391.039516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>205.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>773.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>997.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nb_comments\n",
       "count   823.000000\n",
       "mean    617.393682\n",
       "std     391.039516\n",
       "min       1.000000\n",
       "25%     205.500000\n",
       "50%     773.000000\n",
       "75%     997.000000\n",
       "max    1000.000000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "native_english_df[['nb_comments']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some authors have written only one comments. It's not enough to train a model on it. We have to determine how many comments minimum we should keep and We need to determine how we treat authors who write comments with few words: do we eliminate them, merge their commenters to have longer ones or do we estimate that the number of words is a feature in itself?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('3.10.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63412e708ced85145ee3358b7b7540b5b7bcbe0d3c78f470347fabcaf1a15eaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
