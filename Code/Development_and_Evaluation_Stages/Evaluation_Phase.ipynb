{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-22 11:33:50.959869: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-22 11:33:51.343803: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-22 11:33:51.352373: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-22 11:33:51.352406: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-22 11:33:53.195461: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-22 11:33:53.195666: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-22 11:33:53.195686: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from features_and_svm_functions import *\n",
    "import warnings\n",
    "import yaml # for the config and output files\n",
    "from yaml.loader import SafeLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to input files : they contain the paramters we tuned \n",
    "# Modify it with the actual input files you want to use \n",
    "path_to_input_all    = '../../Data/Inputs/After_Tuning/Input_baseline.yaml' #'Inputs/After_Tuning/Input_tuned_all.yaml'\n",
    "path_to_input_native = '../../Data/Inputs/After_Tuning/Input_baseline.yaml'#'Inputs/After_Tuning/Input_tuned_native.yaml'\n",
    "path_to_input_nonnat = '../../Data/Inputs/After_Tuning/Input_baseline.yaml'#'Inputs/After_Tuning/Input_tuned_nonnative.yaml'\n",
    "path_to_input_max   = '../../Data/Inputs/After_Tuning/Input_max.yaml'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate train and test data for test phase #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read config file :\n",
    "with open(path_to_input_max, 'r') as f:\n",
    "    config_max = list(yaml.load_all(f, Loader=SafeLoader))\n",
    "config_max = config_max[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = config_max['seed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data of the testing set\n",
    "test_100_native_df = pd.read_parquet('../../Data/Test/100native_english',engine='fastparquet')\n",
    "test_100_nonnat_df = pd.read_parquet('../../Data/Test/100non_native_english',engine='fastparquet')\n",
    "test_100_native_df['proficiency'] = \"N\" # N = native\n",
    "test_100_nonnat_df['proficiency'] = \"L\" # L = learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 3*(30 natives, 30 non-natives)\n",
    "num_native_authors_to_sample = 30\n",
    "num_nonnat_authors_to_sample = 30\n",
    "\n",
    "test_100_nonnat_df = test_100_nonnat_df.sample(frac=1)\n",
    "test_100_native_df = test_100_native_df.sample(frac=1)\n",
    "\n",
    "test_native_s1 = test_100_native_df.iloc[0:30,:]   # trial 1\n",
    "test_native_s2 = test_100_native_df.iloc[30:60,:]  # trial 2 \n",
    "test_native_s3 = test_100_native_df.iloc[60:90,:]  # trial 3\n",
    "\n",
    "test_nonnat_s1 = test_100_nonnat_df.iloc[0:30,:]  # trial 1\n",
    "test_nonnat_s2 = test_100_nonnat_df.iloc[30:60,:] # trial 2\n",
    "test_nonnat_s3 = test_100_nonnat_df.iloc[60:90,:] # trial 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing feeds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [02:12<00:00,  9.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feeds tokenized in 132.41242003440857 seconds\n",
      "Tokenizing feeds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [02:16<00:00,  8.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feeds tokenized in 136.97628664970398 seconds\n",
      "Tokenizing feeds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [02:17<00:00,  8.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feeds tokenized in 137.9188461303711 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# build the three sets of (30 native + 30 nonnat) to train and 3*(3*(30+30)) corresponding cohorts \n",
    "s1_cohort_all, s1_cohort_native, s1_cohort_nonnat = build_cohorts(30,30,test_native_s1,test_nonnat_s1,seed)\n",
    "s2_cohort_all, s2_cohort_native, s2_cohort_nonnat = build_cohorts(30,30,test_native_s2,test_nonnat_s2,seed)\n",
    "s3_cohort_all, s3_cohort_native, s3_cohort_nonnat = build_cohorts(30,30,test_native_s3,test_nonnat_s3,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_cohort_all.to_pickle('dataset/Test/s1_cohort_all',protocol=4)\n",
    "s1_cohort_native.to_pickle('dataset/Test/s1_cohort_native',protocol=4) \n",
    "s1_cohort_nonnat.to_pickle('dataset/Test/s1_cohort_nonnat',protocol=4)\n",
    "\n",
    "s2_cohort_all.to_pickle('dataset/Test/s2_cohort_all',protocol=4)\n",
    "s2_cohort_native.to_pickle('dataset/Test/s2_cohort_native',protocol=4)\n",
    "s2_cohort_nonnat.to_pickle('dataset/Test/s2_cohort_nonnat',protocol=4)\n",
    "\n",
    "s3_cohort_all.to_pickle('dataset/Test/s3_cohort_all',protocol=4)\n",
    "s3_cohort_native.to_pickle('dataset/Test/s3_cohort_native',protocol=4) \n",
    "s3_cohort_nonnat.to_pickle('dataset/Test/s3_cohort_nonnat',protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features for these 3 datasets :\n",
    "##### takes about 3-4 hours if done so :\n",
    "#X_train_alls1,X_test_alls1,y_train_alls1,y_test_alls1 = extract_features(s1_cohort_all,config_max,\"all_subset1\")\n",
    "#X_train_alls2,X_test_alls2,y_train_alls2,y_test_alls2 = extract_features(s2_cohort_all,config_max,\"subset2\")\n",
    "#X_train_alls3,X_test_alls3,y_train_alls3,y_test_alls3 = extract_features(s3_cohort_all,config_max,\"subset3\")\n",
    "\n",
    "#X_train_natives1,X_test_natives1,y_train_natives1,y_test_alls1 = extract_features(s1_cohort_all,config_max,\"all_subset1\")\n",
    "#X_train_natives2,X_test_natives2,y_train_natives2,y_test_alls2 = extract_features(s2_cohort_all,config_max,\"subset2\")\n",
    "#X_train_natives3,X_test_natives3,y_train_natives3,y_test_alls3 = extract_features(s3_cohort_all,config_max,\"subset3\")\n",
    "\n",
    "#X_train_alls1,X_test_alls1,y_train_alls1,y_test_alls1 = extract_features(s1_cohort_all,config_max,\"all_subset1\")\n",
    "#X_train_alls2,X_test_alls2,y_train_alls2,y_test_alls2 = extract_features(s2_cohort_all,config_max,\"subset2\")\n",
    "#X_train_alls3,X_test_alls3,y_train_alls3,y_test_alls3 = extract_features(s3_cohort_all,config_max,\"subset3\")\n",
    "\n",
    "##### Otherwise run feature_extraction_for_evaluation_stage.py with arguments 1, 2 and 3 in parallel (2 hours)\n",
    "##### It will save the dataframes with the rigth names etc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION STAGE #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read specific config files for specific models\n",
    "\n",
    "# Config for best mixed classification\n",
    "with open(path_to_input_all, 'r') as f:\n",
    "    config_all = list(yaml.load_all(f, Loader=SafeLoader))\n",
    "config_all = config_all[0]\n",
    "\n",
    "# Config for best native classification\n",
    "with open(path_to_input_native, 'r') as f:\n",
    "    config_native = list(yaml.load_all(f, Loader=SafeLoader))\n",
    "config_native = config_native[0]\n",
    "\n",
    "# Config for best nonnative classification\n",
    "with open(path_to_input_nonnat, 'r') as f:\n",
    "    config_nonnat = list(yaml.load_all(f, Loader=SafeLoader))\n",
    "config_nonnat = config_nonnat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and test data\n",
    "# Divided in three samples --> we will average the results \n",
    "# Each model we will train will be trained and tested for the same authors = need just 3 sets of t\n",
    "path_to_dataset = '../../Data/Test/'\n",
    "\n",
    "# COHORT ALL, data for trials 1 2 and 3\n",
    "X_train_all_s1 = pd.read_parquet(path_to_dataset+'X_train_all_s1',engine='fastparquet')\n",
    "X_test_all_s1  = pd.read_parquet(path_to_dataset+'X_test_all_s1',engine='fastparquet')\n",
    "y_train_all_s1 = pd.read_parquet(path_to_dataset+'y_train_all_s1',engine='fastparquet')\n",
    "y_test_all_s1  = pd.read_parquet(path_to_dataset+'y_test_all_s1',engine='fastparquet')\n",
    "\n",
    "X_train_all_s2 = pd.read_parquet(path_to_dataset+'X_train_all_s2',engine='fastparquet')\n",
    "X_test_all_s2  = pd.read_parquet(path_to_dataset+'X_test_all_s2',engine='fastparquet')\n",
    "y_train_all_s2 = pd.read_parquet(path_to_dataset+'y_train_all_s2',engine='fastparquet')\n",
    "y_test_all_s2  = pd.read_parquet(path_to_dataset+'y_test_all_s2',engine='fastparquet')\n",
    "\n",
    "X_train_all_s3 = pd.read_parquet(path_to_dataset+'X_train_all_s3',engine='fastparquet')\n",
    "X_test_all_s3  = pd.read_parquet(path_to_dataset+'X_test_all_s3',engine='fastparquet')\n",
    "y_train_all_s3 = pd.read_parquet(path_to_dataset+'y_train_all_s3',engine='fastparquet')\n",
    "y_test_all_s3  = pd.read_parquet(path_to_dataset+'y_test_all_s3',engine='fastparquet')\n",
    "\n",
    "\n",
    "\n",
    "# COHORT NATIVE,, data for trials 1 2 and 3 \n",
    "X_train_native_s1 = pd.read_parquet(path_to_dataset+'X_train_native_s1',engine='fastparquet')\n",
    "X_test_native_s1  = pd.read_parquet(path_to_dataset+'X_test_native_s1',engine='fastparquet')\n",
    "y_train_native_s1 = pd.read_parquet(path_to_dataset+'y_train_native_s1',engine='fastparquet')\n",
    "y_test_native_s1  = pd.read_parquet(path_to_dataset+'y_test_native_s1',engine='fastparquet')\n",
    "\n",
    "X_train_native_s2 = pd.read_parquet(path_to_dataset+'X_train_native_s2',engine='fastparquet')\n",
    "X_test_native_s2  = pd.read_parquet(path_to_dataset+'X_test_native_s2',engine='fastparquet')\n",
    "y_train_native_s2 = pd.read_parquet(path_to_dataset+'y_train_native_s2',engine='fastparquet')\n",
    "y_test_native_s2  = pd.read_parquet(path_to_dataset+'y_test_native_s2',engine='fastparquet')\n",
    "\n",
    "X_train_native_s3 = pd.read_parquet(path_to_dataset+'X_train_native_s3',engine='fastparquet')\n",
    "X_test_native_s3  = pd.read_parquet(path_to_dataset+'X_test_native_s3',engine='fastparquet')\n",
    "y_train_native_s3 = pd.read_parquet(path_to_dataset+'y_train_native_s3',engine='fastparquet')\n",
    "y_test_native_s3  = pd.read_parquet(path_to_dataset+'y_test_native_s3',engine='fastparquet')\n",
    "\n",
    "\n",
    "\n",
    "# COHORT NONNAT, , data for trials 1 2 and 3\n",
    "X_train_nonnat_s1 = pd.read_parquet(path_to_dataset+'X_train_nonnat_s1',engine='fastparquet')\n",
    "X_test_nonnat_s1  = pd.read_parquet(path_to_dataset+'X_test_nonnat_s1',engine='fastparquet')\n",
    "y_train_nonnat_s1 = pd.read_parquet(path_to_dataset+'y_train_nonnat_s1',engine='fastparquet')\n",
    "y_test_nonnat_s1  = pd.read_parquet(path_to_dataset+'y_test_nonnat_s1',engine='fastparquet')\n",
    "\n",
    "X_train_nonnat_s2 = pd.read_parquet(path_to_dataset+'X_train_nonnat_s2',engine='fastparquet')\n",
    "X_test_nonnat_s2  = pd.read_parquet(path_to_dataset+'X_test_nonnat_s2',engine='fastparquet')\n",
    "y_train_nonnat_s2 = pd.read_parquet(path_to_dataset+'y_train_nonnat_s2',engine='fastparquet')\n",
    "y_test_nonnat_s2  = pd.read_parquet(path_to_dataset+'y_test_nonnat_s2',engine='fastparquet')\n",
    "\n",
    "X_train_nonnat_s3 = pd.read_parquet(path_to_dataset+'X_train_nonnat_s3',engine='fastparquet')\n",
    "X_test_nonnat_s3  = pd.read_parquet(path_to_dataset+'X_test_nonnat_s3',engine='fastparquet')\n",
    "y_train_nonnat_s3 = pd.read_parquet(path_to_dataset+'y_train_nonnat_s3',engine='fastparquet')\n",
    "y_test_nonnat_s3  = pd.read_parquet(path_to_dataset+'y_test_nonnat_s3',engine='fastparquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRIAL 1\n",
    "\n",
    "# Performing the test for configuration 'all' :\n",
    "\n",
    "# ...on all\n",
    "res_all_on_all_1    = classify_with_input('all_on_all_1',config_all,X_train_all_s1,X_test_all_s1,y_train_all_s1,y_test_all_s1)\n",
    "# ... on native\n",
    "res_all_on_native_1 = classify_with_input('all_on_native_1',config_all,X_train_native_s1,X_test_native_s1,y_train_native_s1,y_test_native_s1)\n",
    "# ... on nonnnat\n",
    "res_all_on_nonnat_1 = classify_with_input('all_on_nonnat_1',config_all,X_train_nonnat_s1,X_test_nonnat_s1,y_train_nonnat_s1,y_test_nonnat_s1)\n",
    "\n",
    "# Performing the test for configuration 'native' :\n",
    "\n",
    "# ...on all\n",
    "res_native_on_all_1    = classify_with_input('native_on_all_1',config_native,X_train_all_s1,X_test_all_s1,y_train_all_s1,y_test_all_s1)\n",
    "# ... on native\n",
    "res_native_on_native_1 = classify_with_input('native_on_native_1',config_native,X_train_native_s1,X_test_native_s1,y_train_native_s1,y_test_native_s1)\n",
    "# ... on nonnnat\n",
    "res_native_on_nonnat_1 = classify_with_input('native_on_nonnat_1',config_native,X_train_nonnat_s1,X_test_nonnat_s1,y_train_nonnat_s1,y_test_nonnat_s1)\n",
    "\n",
    "# Performing the test for configuration 'non native' :\n",
    "# ...on all\n",
    "res_nonnat_on_all_1    = classify_with_input('nonnat_on_all_1',config_nonnat,X_train_all_s1,X_test_all_s1,y_train_all_s1,y_test_all_s1)\n",
    "# ... on native\n",
    "res_nonnat_on_native_1 = classify_with_input('nonnat_on_native_1',config_nonnat,X_train_native_s1,X_test_native_s1,y_train_native_s1,y_test_native_s1)\n",
    "# ... on nonnnat\n",
    "res_nonnat_on_nonnat_1 = classify_with_input('nonnat_on_nonnat_1',config_nonnat,X_train_nonnat_s1,X_test_nonnat_s1,y_train_nonnat_s1,y_test_nonnat_s1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRIAL 2\n",
    "\n",
    "# Performing the test for configuration 'all' :\n",
    "\n",
    "# ...on all\n",
    "res_all_on_all_2    = classify_with_input('all_on_all_2',config_all,X_train_all_s2,X_test_all_s2,y_train_all_s2,y_test_all_s2)\n",
    "# ... on native\n",
    "res_all_on_native_2 = classify_with_input('all_on_native_2',config_all,X_train_native_s2,X_test_native_s2,y_train_native_s2,y_test_native_s2)\n",
    "# ... on nonnnat\n",
    "res_all_on_nonnat_2 = classify_with_input('all_on_nonnat_2',config_all,X_train_nonnat_s2,X_test_nonnat_s2,y_train_nonnat_s2,y_test_nonnat_s2)\n",
    "\n",
    "# Performing the test for configuration 'native' :\n",
    "\n",
    "# ...on all\n",
    "res_native_on_all_2    = classify_with_input('native_on_all_2',config_native,X_train_all_s2,X_test_all_s2,y_train_all_s2,y_test_all_s2)\n",
    "# ... on native\n",
    "res_native_on_native_2 = classify_with_input('native_on_native_2',config_native,X_train_native_s2,X_test_native_s2,y_train_native_s2,y_test_native_s2)\n",
    "# ... on nonnnat\n",
    "res_native_on_nonnat_2 = classify_with_input('native_on_nonnat_2',config_native,X_train_nonnat_s2,X_test_nonnat_s2,y_train_nonnat_s2,y_test_nonnat_s2)\n",
    "\n",
    "# Performing the test for configuration 'non native' :\n",
    "# ...on all\n",
    "res_nonnat_on_all_2    = classify_with_input('nonnat_on_all_2',config_nonnat,X_train_all_s2,X_test_all_s2,y_train_all_s2,y_test_all_s2)\n",
    "# ... on native\n",
    "res_nonnat_on_native_2 = classify_with_input('nonnat_on_native_2',config_nonnat,X_train_native_s2,X_test_native_s2,y_train_native_s2,y_test_native_s2)\n",
    "# ... on nonnnat\n",
    "res_nonnat_on_nonnat_2 = classify_with_input('nonnat_on_nonnat_2',config_nonnat,X_train_nonnat_s2,X_test_nonnat_s2,y_train_nonnat_s2,y_test_nonnat_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRIAL 3\n",
    "\n",
    "# Performing the test for configuration 'all' :\n",
    "\n",
    "# ...on all\n",
    "res_all_on_all_3    = classify_with_input('all_on_all_3',config_all,X_train_all_s3,X_test_all_s3,y_train_all_s3,y_test_all_s3)\n",
    "# ... on native\n",
    "res_all_on_native_3 = classify_with_input('all_on_native_3',config_all,X_train_native_s3,X_test_native_s3,y_train_native_s3,y_test_native_s3)\n",
    "# ... on nonnnat\n",
    "res_all_on_nonnat_3 = classify_with_input('all_on_nonnat_3',config_all,X_train_nonnat_s3,X_test_nonnat_s3,y_train_nonnat_s3,y_test_nonnat_s3)\n",
    "\n",
    "# Performing the test for configuration 'native' :\n",
    "\n",
    "# ...on all\n",
    "res_native_on_all_3    = classify_with_input('native_on_all_3',config_native,X_train_all_s3,X_test_all_s3,y_train_all_s3,y_test_all_s3)\n",
    "# ... on native\n",
    "res_native_on_native_3 = classify_with_input('native_on_native_3',config_native,X_train_native_s3,X_test_native_s3,y_train_native_s3,y_test_native_s3)\n",
    "# ... on nonnnat\n",
    "res_native_on_nonnat_3 = classify_with_input('native_on_nonnat_3',config_native,X_train_nonnat_s3,X_test_nonnat_s3,y_train_nonnat_s3,y_test_nonnat_s3)\n",
    "\n",
    "# Performing the test for configuration 'non native' :\n",
    "# ...on all\n",
    "res_nonnat_on_all_3    = classify_with_input('nonnat_on_all_3',config_nonnat,X_train_all_s3,X_test_all_s3,y_train_all_s3,y_test_all_s3)\n",
    "# ... on native\n",
    "res_nonnat_on_native_3 = classify_with_input('nonnat_on_native_3',config_nonnat,X_train_native_s3,X_test_native_s3,y_train_native_s3,y_test_native_s3)\n",
    "# ... on nonnnat\n",
    "res_nonnat_on_nonnat_3 = classify_with_input('nonnat_on_nonnat_3',config_nonnat,X_train_nonnat_s3,X_test_nonnat_s3,y_train_nonnat_s3,y_test_nonnat_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average acc and f1 over the three trials :\n",
    "# models all_on_....\n",
    "average_all_on_all = np.array([1./3.*(float(res_all_on_all_1['Model all_on_all_1']['Accuracy']['Overall'])\n",
    "                                     +float(res_all_on_all_2['Model all_on_all_2']['Accuracy']['Overall'])\n",
    "                                     +float(res_all_on_all_3['Model all_on_all_3']['Accuracy']['Overall'])),\n",
    "                               1./3.*(float(res_all_on_all_1['Model all_on_all_1']['F1']['Overall'])\n",
    "                                     +float(res_all_on_all_2['Model all_on_all_2']['F1']['Overall'])\n",
    "                                    +float(res_all_on_all_3['Model all_on_all_3']['F1']['Overall']))])\n",
    "average_all_on_native = np.array([1./3.*(float(res_all_on_native_1['Model all_on_native_1']['Accuracy']['Native'])\n",
    "                                        +float(res_all_on_native_2['Model all_on_native_2']['Accuracy']['Native'])\n",
    "                                        +float(res_all_on_native_3['Model all_on_native_3']['Accuracy']['Native'])),\n",
    "                                  1./3.*(float(res_all_on_native_1['Model all_on_native_1']['F1']['Native'])\n",
    "                                        +float(res_all_on_native_2['Model all_on_native_2']['F1']['Native']))])\n",
    "average_all_on_nonnat = np.array([1./3.*(float(res_all_on_nonnat_1['Model all_on_nonnat_1']['Accuracy']['Non_Native'])\n",
    "                                    +float(res_all_on_nonnat_2['Model all_on_nonnat_2']['Accuracy']['Non_Native'])\n",
    "                                    +float(res_all_on_nonnat_3['Model all_on_nonnat_3']['Accuracy']['Non_Native'])),\n",
    "                               1./3.*(float(res_all_on_nonnat_1['Model all_on_nonnat_1']['F1']['Non_Native'])\n",
    "                                    +float(res_all_on_nonnat_2['Model all_on_nonnat_2']['F1']['Non_Native'])\n",
    "                                    +float(res_all_on_nonnat_3['Model all_on_nonnat_3']['F1']['Non_Native']))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models native_on_....\n",
    "average_native_on_all = np.array([1./3.*(float(res_native_on_all_1['Model native_on_all_1']['Accuracy']['Overall'])\n",
    "                                    +float(res_native_on_all_2['Model native_on_all_2']['Accuracy']['Overall'])\n",
    "                                    +float(res_native_on_all_3['Model native_on_all_3']['Accuracy']['Overall'])),\n",
    "                               1./3.*(float(res_native_on_all_1['Model native_on_all_1']['F1']['Overall'])\n",
    "                                    +float(res_native_on_all_2['Model native_on_all_2']['F1']['Overall'])\n",
    "                                    +float(res_native_on_all_3['Model native_on_all_3']['F1']['Overall']))])\n",
    "average_native_on_native = np.array([1./3.*(float(res_native_on_native_1['Model native_on_native_1']['Accuracy']['Native'])\n",
    "                                       +float(res_native_on_native_2['Model native_on_native_2']['Accuracy']['Native'])\n",
    "                                       +float(res_native_on_native_3['Model native_on_native_3']['Accuracy']['Native'])),\n",
    "                               1./3.*(float(res_native_on_native_1['Model native_on_native_1']['F1']['Native'])\n",
    "                                    +float(res_native_on_native_2['Model native_on_native_2']['F1']['Native'])\n",
    "                                    +float(res_native_on_native_3['Model native_on_native_3']['F1']['Native']))])\n",
    "average_native_on_nonnat = np.array([1./3.*(float(res_native_on_nonnat_1['Model native_on_nonnat_1']['Accuracy']['Non_Native'])\n",
    "                                    +float(res_native_on_nonnat_2['Model native_on_nonnat_2']['Accuracy']['Non_Native'])\n",
    "                                    +float(res_native_on_nonnat_3['Model native_on_nonnat_3']['Accuracy']['Non_Native'])),\n",
    "                               1./3.*(float(res_native_on_nonnat_1['Model native_on_nonnat_1']['F1']['Non_Native'])\n",
    "                                    +float(res_native_on_nonnat_2['Model native_on_nonnat_2']['F1']['Non_Native'])\n",
    "                                    +float(res_native_on_nonnat_3['Model native_on_nonnat_3']['F1']['Non_Native']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models nonnat_on_....\n",
    "\n",
    "average_nonnat_on_all = np.array([1./3.*(float(res_nonnat_on_all_1['Model nonnat_on_all_1']['Accuracy']['Overall'])\n",
    "                                    +float(res_nonnat_on_all_2['Model nonnat_on_all_2']['Accuracy']['Overall'])\n",
    "                                    +float(res_nonnat_on_all_3['Model nonnat_on_all_3']['Accuracy']['Overall'])),\n",
    "                               1./3.*(float(res_nonnat_on_all_1['Model nonnat_on_all_1']['F1']['Overall'])\n",
    "                                    +float(res_nonnat_on_all_2['Model nonnat_on_all_2']['F1']['Overall'])\n",
    "                                    +float(res_nonnat_on_all_3['Model nonnat_on_all_3']['F1']['Overall']))])\n",
    "average_nonnat_on_native = np.array([1./3.*(float(res_nonnat_on_native_1['Model nonnat_on_native_1']['Accuracy']['Native'])\n",
    "                                       +float(res_nonnat_on_native_2['Model nonnat_on_native_2']['Accuracy']['Native'])\n",
    "                                       +float(res_nonnat_on_native_3['Model nonnat_on_native_3']['Accuracy']['Native'])),\n",
    "                               1./3.*(float(res_nonnat_on_native_1['Model nonnat_on_native_1']['F1']['Native'])\n",
    "                                    +float(res_nonnat_on_native_2['Model nonnat_on_native_2']['F1']['Native'])\n",
    "                                    +float(res_nonnat_on_native_3['Model nonnat_on_native_3']['F1']['Native']))])\n",
    "average_nonnat_on_nonnat = np.array([1./3.*(float(res_nonnat_on_nonnat_1['Model nonnat_on_nonnat_1']['Accuracy']['Non_Native'])\n",
    "                                    +float(res_nonnat_on_nonnat_2['Model nonnat_on_nonnat_2']['Accuracy']['Non_Native'])\n",
    "                                    +float(res_nonnat_on_nonnat_3['Model nonnat_on_nonnat_3']['Accuracy']['Non_Native'])),\n",
    "                               1./3.*(float(res_nonnat_on_nonnat_1['Model nonnat_on_nonnat_1']['F1']['Non_Native'])\n",
    "                                    +float(res_nonnat_on_nonnat_2['Model nonnat_on_nonnat_2']['F1']['Non_Native'])\n",
    "                                    +float(res_nonnat_on_nonnat_3['Model nonnat_on_nonnat_3']['F1']['Non_Native']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionnary of all averages \n",
    "dict = {'Parameters -all-': {'Data -all-':    {'Accuracy (avg)':float(average_all_on_all[0]),'F1 (avg)':float(average_all_on_all[1])},\n",
    "                             'Data -native-': {'Accuracy (avg)':float(average_all_on_native[0]),'F1 (avg)':float(average_all_on_native[1])},\n",
    "                             'Data -nonnat-': {'Accuracy (avg)':float(average_all_on_nonnat[0]),'F1 (avg)':float(average_all_on_nonnat[1])}},\n",
    "        'Parameters -native-' : {'Data -all-':    {'Accuracy (avg)':float(average_native_on_all[0]),'F1 (avg)':float(average_native_on_all[1])},\n",
    "                                 'Data -native-': {'Accuracy (avg)':float(average_native_on_native[0]),'F1 (avg)':float(average_native_on_native[1])},\n",
    "                                 'Data -nonnat-': {'Accuracy (avg)':float(average_native_on_nonnat[0]),'F1 (avg)':float(average_native_on_nonnat[1])}},\n",
    "        'Parameters -nonnat-': {'Data -all-':    {'Accuracy (avg)':float(average_nonnat_on_all[0]),'F1 (avg)':float(average_nonnat_on_all[1])},\n",
    "                                'Data -native-': {'Accuracy (avg)':float(average_nonnat_on_native[0]),'F1 (avg)':float(average_nonnat_on_native[1])},\n",
    "                                'Data -nonnat-': {'Accuracy (avg)':float(average_nonnat_on_nonnat[0]),'F1 (avg)':float(average_nonnat_on_nonnat[1])}}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it\n",
    "\n",
    "with open('Outputs/RESULTS_TEST_STAGE.yaml', 'w') as file:\n",
    "    yaml.dump(dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate dictionnaries for each trial and save them \n",
    "\n",
    "dict_1 = {'Parameters -all-': {'Data -all-'   : {'Accuracy':float(res_all_on_all_1['Model all_on_all_1']['Accuracy']['Overall']),'F1':float(res_all_on_all_1['Model all_on_all_1']['F1']['Overall']),\n",
    "                                                 'Subset Native':{'Accuracy' : float(res_all_on_all_1['Model all_on_all_1']['Accuracy']['Native']),'F1':float(res_all_on_all_1['Model all_on_all_1']['F1']['Native'])},\n",
    "                                                 'Subset Nonnat':{'Accuracy' : float(res_all_on_all_1['Model all_on_all_1']['Accuracy']['Non_Native']),'F1':float(res_all_on_all_1['Model all_on_all_1']['F1']['Non_Native'])}},\n",
    "                             'Data -native-': {'Accuracy':float(res_all_on_native_1['Model all_on_native_1']['Accuracy']['Native']),'F1':float(res_all_on_native_1['Model all_on_native_1']['F1']['Native'])},\n",
    "                             'Data -nonnat-': {'Accuracy':float(res_all_on_nonnat_1['Model all_on_nonnat_1']['Accuracy']['Non_Native']),'F1':float(res_all_on_nonnat_1['Model all_on_nonnat_1']['F1']['Non_Native'])}},\n",
    "        'Parameters -native-' : {'Data -all-':  {'Accuracy':float(res_native_on_all_1['Model native_on_all_1']['Accuracy']['Overall']),'F1':float(res_native_on_all_1['Model native_on_all_1']['F1']['Overall']),\n",
    "                                                 'Subset Native':{'Accuracy' : float(res_native_on_all_1['Model native_on_all_1']['Accuracy']['Native']),'F1':float(res_native_on_all_1['Model native_on_all_1']['F1']['Native'])},\n",
    "                                                 'Subset Nonnat':{'Accuracy' : float(res_native_on_all_1['Model native_on_all_1']['Accuracy']['Non_Native']),'F1':float(res_native_on_all_1['Model native_on_all_1']['F1']['Non_Native'])}},\n",
    "                                 'Data -native-': {'Accuracy':float(res_native_on_native_1['Model native_on_native_1']['Accuracy']['Native']),'F1':float(res_native_on_native_1['Model native_on_native_1']['F1']['Native'])},\n",
    "                                 'Data -nonnat-': {'Accuracy':float(res_native_on_nonnat_1['Model native_on_nonnat_1']['Accuracy']['Non_Native']),'F1':float(res_native_on_nonnat_1['Model native_on_nonnat_1']['F1']['Non_Native'])}},\n",
    "        'Parameters -nonnat-': {'Data -all-':    {'Accuracy':float(res_nonnat_on_all_1['Model nonnat_on_all_1']['Accuracy']['Overall']),'F1':float(res_nonnat_on_all_1['Model nonnat_on_all_1']['F1']['Overall']),\n",
    "                                                  'Subset Native':{'Accuracy' : float(res_nonnat_on_all_1['Model nonnat_on_all_1']['Accuracy']['Native']),'F1':float(res_nonnat_on_all_1['Model nonnat_on_all_1']['F1']['Native'])},\n",
    "                                                  'Subset Nonnat':{'Accuracy' : float(res_nonnat_on_all_1['Model nonnat_on_all_1']['Accuracy']['Non_Native']),'F1':float(res_nonnat_on_all_1['Model nonnat_on_all_1']['F1']['Non_Native'])}},\n",
    "                                'Data -native-': {'Accuracy':float(res_nonnat_on_native_1['Model nonnat_on_native_1']['Accuracy']['Native']),'F1':float(res_nonnat_on_native_1['Model nonnat_on_native_1']['F1']['Native'])},\n",
    "                                'Data -nonnat-': {'Accuracy':float(res_nonnat_on_nonnat_1['Model nonnat_on_nonnat_1']['Accuracy']['Non_Native']),'F1':float(res_nonnat_on_nonnat_1['Model nonnat_on_nonnat_1']['F1']['Non_Native'])}}}\n",
    "with open('Outputs/RESULTS_TEST_STAGE_BASELINE_TRIAL_1.yaml', 'w') as file:\n",
    "    yaml.dump(dict_1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_2 = {'Parameters -all-': {'Data -all-'   : {'Accuracy':float(res_all_on_all_2['Model all_on_all_2']['Accuracy']['Overall']),'F1':float(res_all_on_all_2['Model all_on_all_2']['F1']['Overall']),\n",
    "                                                 'Subset Native':{'Accuracy' : float(res_all_on_all_2['Model all_on_all_2']['Accuracy']['Native']),'F1':float(res_all_on_all_2['Model all_on_all_2']['F1']['Native'])},\n",
    "                                                 'Subset Nonnat':{'Accuracy' : float(res_all_on_all_2['Model all_on_all_2']['Accuracy']['Non_Native']),'F1':float(res_all_on_all_2['Model all_on_all_2']['F1']['Non_Native'])}},\n",
    "                             'Data -native-': {'Accuracy':float(res_all_on_native_2['Model all_on_native_2']['Accuracy']['Native']),'F1':float(res_all_on_native_2['Model all_on_native_2']['F1']['Native'])},\n",
    "                             'Data -nonnat-': {'Accuracy':float(res_all_on_nonnat_2['Model all_on_nonnat_2']['Accuracy']['Non_Native']),'F1':float(res_all_on_nonnat_2['Model all_on_nonnat_2']['F1']['Non_Native'])}},\n",
    "        'Parameters -native-' : {'Data -all-':    {'Accuracy':float(res_native_on_all_2['Model native_on_all_2']['Accuracy']['Overall']),'F1':float(res_native_on_all_2['Model native_on_all_2']['F1']['Overall']),\n",
    "                                                 'Subset Native':{'Accuracy' : float(res_native_on_all_2['Model native_on_all_2']['Accuracy']['Native']),'F1':float(res_native_on_all_2['Model native_on_all_2']['F1']['Native'])},\n",
    "                                                 'Subset Nonnat':{'Accuracy' : float(res_native_on_all_2['Model native_on_all_2']['Accuracy']['Non_Native']),'F1':float(res_native_on_all_2['Model native_on_all_2']['F1']['Non_Native'])}},\n",
    "                                 'Data -native-': {'Accuracy':float(res_native_on_native_2['Model native_on_native_2']['Accuracy']['Native']),'F1':float(res_native_on_native_2['Model native_on_native_2']['F1']['Native'])},\n",
    "                                 'Data -nonnat-': {'Accuracy':float(res_native_on_nonnat_2['Model native_on_nonnat_2']['Accuracy']['Non_Native']),'F1':float(res_native_on_nonnat_2['Model native_on_nonnat_2']['F1']['Non_Native'])}},\n",
    "        'Parameters -nonnat-': {'Data -all-':    {'Accuracy':float(res_nonnat_on_all_2['Model nonnat_on_all_2']['Accuracy']['Overall']),'F1':float(res_nonnat_on_all_2['Model nonnat_on_all_2']['F1']['Overall']),\n",
    "                                                  'Subset Native':{'Accuracy' : float(res_nonnat_on_all_2['Model nonnat_on_all_2']['Accuracy']['Native']),'F1':float(res_nonnat_on_all_2['Model nonnat_on_all_2']['F1']['Native'])},\n",
    "                                                  'Subset Nonnat':{'Accuracy' : float(res_nonnat_on_all_2['Model nonnat_on_all_2']['Accuracy']['Non_Native']),'F1':float(res_nonnat_on_all_2['Model nonnat_on_all_2']['F1']['Non_Native'])}},\n",
    "                                'Data -native-': {'Accuracy':float(res_nonnat_on_native_2['Model nonnat_on_native_2']['Accuracy']['Native']),'F1':float(res_nonnat_on_native_2['Model nonnat_on_native_2']['F1']['Native'])},\n",
    "                                'Data -nonnat-': {'Accuracy':float(res_nonnat_on_nonnat_2['Model nonnat_on_nonnat_2']['Accuracy']['Non_Native']),'F1':float(res_nonnat_on_nonnat_2['Model nonnat_on_nonnat_2']['F1']['Non_Native'])}}}\n",
    "with open('Outputs/RESULTS_TEST_STAGE_BASELINE_TRIAL_2.yaml', 'w') as file:\n",
    "    yaml.dump(dict_2, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_3 = {'Parameters -all-': {'Data -all-'   : {'Accuracy':float(res_all_on_all_3['Model all_on_all_3']['Accuracy']['Overall']),'F1':float(res_all_on_all_3['Model all_on_all_3']['F1']['Overall']),\n",
    "                                                 'Subset Native':{'Accuracy' : float(res_all_on_all_3['Model all_on_all_3']['Accuracy']['Native']),'F1':float(res_all_on_all_3['Model all_on_all_3']['F1']['Native'])},\n",
    "                                                 'Subset Nonnat':{'Accuracy' : float(res_all_on_all_3['Model all_on_all_3']['Accuracy']['Non_Native']),'F1':float(res_all_on_all_3['Model all_on_all_3']['F1']['Non_Native'])}},\n",
    "                             'Data -native-': {'Accuracy':float(res_all_on_native_3['Model all_on_native_3']['Accuracy']['Native']),'F1':float(res_all_on_native_3['Model all_on_native_3']['F1']['Native'])},\n",
    "                             'Data -nonnat-': {'Accuracy':float(res_all_on_nonnat_3['Model all_on_nonnat_3']['Accuracy']['Non_Native']),'F1':float(res_all_on_nonnat_3['Model all_on_nonnat_3']['F1']['Non_Native'])}},\n",
    "        'Parameters -native-' : {'Data -all-':    {'Accuracy':float(res_native_on_all_3['Model native_on_all_3']['Accuracy']['Overall']),'F1':float(res_native_on_all_3['Model native_on_all_3']['F1']['Overall']),\n",
    "                                                 'Subset Native':{'Accuracy' : float(res_native_on_all_3['Model native_on_all_3']['Accuracy']['Native']),'F1':float(res_native_on_all_3['Model native_on_all_3']['F1']['Native'])},\n",
    "                                                 'Subset Nonnat':{'Accuracy' : float(res_native_on_all_3['Model native_on_all_3']['Accuracy']['Non_Native']),'F1':float(res_native_on_all_3['Model native_on_all_3']['F1']['Non_Native'])}},\n",
    "                                 'Data -native-': {'Accuracy':float(res_native_on_native_3['Model native_on_native_3']['Accuracy']['Native']),'F1':float(res_native_on_native_3['Model native_on_native_3']['F1']['Native'])},\n",
    "                                 'Data -nonnat-': {'Accuracy':float(res_native_on_nonnat_3['Model native_on_nonnat_3']['Accuracy']['Non_Native']),'F1':float(res_native_on_nonnat_3['Model native_on_nonnat_3']['F1']['Non_Native'])}},\n",
    "        'Parameters -nonnat-': {'Data -all-':    {'Accuracy':float(res_nonnat_on_all_3['Model nonnat_on_all_3']['Accuracy']['Overall']),'F1':float(res_nonnat_on_all_3['Model nonnat_on_all_3']['F1']['Overall']),\n",
    "                                                  'Subset Native':{'Accuracy' : float(res_nonnat_on_all_3['Model nonnat_on_all_3']['Accuracy']['Native']),'F1':float(res_nonnat_on_all_3['Model nonnat_on_all_3']['F1']['Native'])},\n",
    "                                                  'Subset Nonnat':{'Accuracy' : float(res_nonnat_on_all_3['Model nonnat_on_all_3']['Accuracy']['Non_Native']),'F1':float(res_nonnat_on_all_3['Model nonnat_on_all_3']['F1']['Non_Native'])}},\n",
    "                                'Data -native-': {'Accuracy':float(res_nonnat_on_native_3['Model nonnat_on_native_3']['Accuracy']['Native']),'F1':float(res_nonnat_on_native_3['Model nonnat_on_native_3']['F1']['Native'])},\n",
    "                                'Data -nonnat-': {'Accuracy':float(res_nonnat_on_nonnat_3['Model nonnat_on_nonnat_3']['Accuracy']['Non_Native']),'F1':float(res_nonnat_on_nonnat_3['Model nonnat_on_nonnat_3']['F1']['Non_Native'])}}}\n",
    "with open('Outputs/RESULTS_TEST_STAGE_BASELINE_TRIAL_3.yaml', 'w') as file:\n",
    "    yaml.dump(dict_3, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
